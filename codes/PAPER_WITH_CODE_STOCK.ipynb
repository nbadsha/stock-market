{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPciVgzoYt1i9wragcJ8YP6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"dj6NJk83qJpY"},"outputs":[],"source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","# In[1]:\n","\n","\n","import json\n","import time\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import datetime as dt\n","from numpy import newaxis\n","from keras.layers import Dense, Activation, Dropout, LSTM\n","from keras.models import Sequential, load_model\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.linear_model import LinearRegression\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import Ridge\n","from math import pi,sqrt,exp,pow,log\n","from numpy.linalg import det, inv\n","from abc import ABCMeta, abstractmethod\n","from sklearn import cluster\n","from tensorflow import keras\n","from sklearn.preprocessing import MinMaxScaler\n","import statsmodels.api as sm \n","import scipy.stats as scs\n","import scipy.optimize as sco\n","import scipy.interpolate as sci\n","from scipy import stats\n","\n","import keras_tuner\n","\n","\n","# In[42]:\n","\n","# scld_window = scaler.fit_transform(window_data[0].flatten().reshape(-1,1))\n","\n","def df_index_alter(df):\n","    df = df.sort_values(by=['Date'],ascending=True)\n","    # setting the index as date\n","    df.index = df['Date']\n","    # drop date column as it is now index column\n","    df = df.drop(['Date'],axis=1)\n","    return df\n","\n","\n","def data_preprocess(dataframe, cols, sequence_length,split):\n","    \n","    len_dataframe=dataframe.shape[0]\n","    \n","    i_split = int(len(dataframe) * split)\n","    data_train = dataframe.get(cols).values[:i_split]\n","    data_test  = dataframe.get(cols).values[i_split:]\n","    len_train  = len(data_train)\n","    len_test   = len(data_test)\n","    len_train_windows = None\n","    print('data_train.shape',data_train.shape)\n","    print('data_test.shape',data_test.shape)\n","    \n","    #get_test_data    \n","    data_windows = []\n","    for i in range(len_test - sequence_length):\n","        data_windows.append(data_test[i:i+sequence_length])\n","    data_windows = np.array(data_windows).astype(float)\n","     # get original y_test\n","    y_test_ori = data_windows[:, -1, [0]]\n","    print('y_test_ori.shape',y_test_ori.shape)\n","    \n","    window_data=data_windows\n","    win_num=window_data.shape[0]\n","    col_num=window_data.shape[2]\n","    normalised_data = []\n","    record_min=[]\n","    record_max=[]\n","    \n","    #normalize\n","    for win_i in range(0,win_num):\n","        normalised_window = []\n","        for col_i in range(0,col_num):\n","          temp_col=window_data[win_i,:,col_i]\n","          temp_min=min(temp_col)\n","          if col_i==0:\n","            record_min.append(temp_min)#record min\n","          temp_col=temp_col-temp_min\n","          temp_max=max(temp_col)\n","          if col_i==0:\n","            record_max.append(temp_max)#record max\n","          temp_col=temp_col/temp_max\n","          normalised_window.append(temp_col)\n","        normalised_window = np.array(normalised_window).T\n","        normalised_data.append(normalised_window)\n","    normalised_data=np.array(normalised_data)\n","    \n","    # normalised_data=window_data\n","    data_windows=normalised_data#get_test_data\n","    x_test = data_windows[:, :-1]\n","    y_test = data_windows[:, -1, [0]]\n","    print('x_test.shape',x_test.shape)\n","    print('y_test.shape',y_test.shape)\n","    \n","    #get_train_data \n","    data_windows = []\n","    for i in range(len_train - sequence_length):\n","        data_windows.append(data_train[i:i+sequence_length])\n","    data_windows = np.array(data_windows).astype(float)\n","      \n","    window_data=data_windows\n","    win_num=window_data.shape[0]\n","    col_num=window_data.shape[2]\n","    \n","    normalised_data = []\n","    for win_i in range(0,win_num):\n","        normalised_window = []\n","        for col_i in range(0,col_num):\n","          temp_col=window_data[win_i,:,col_i]\n","          temp_min=min(temp_col)\n","          temp_col=temp_col-temp_min\n","          temp_max=max(temp_col)\n","          temp_col=temp_col/temp_max\n","          normalised_window.append(temp_col)\n","        normalised_window = np.array(normalised_window).T\n","        normalised_data.append(normalised_window)\n","    normalised_data=np.array(normalised_data)\n","    \n","    # normalised_data=window_data\n","    data_windows=normalised_data\n","    x_train = data_windows[:, :-1]\n","    y_train = data_windows[:, -1,[0]]\n","    print('x_train.shape',x_train.shape)\n","    print('y_train.shape',y_train.shape)\n","    return x_train, y_train, x_test, y_test, y_test_ori, record_max, record_min\n","\n","\n","# In[43]:\n","\n","    \n","# def call_existing_code(units, activation, dropout, lr):\n","#     model = keras.Sequential()\n","#     model.add(layers.Flatten())\n","#     model.add(layers.Dense(units=units, activation=activation))\n","#     if dropout:\n","#         model.add(layers.Dropout(rate=0.25))\n","#     model.add(layers.Dense(10, activation=\"softmax\"))\n","#     model.compile(\n","#         optimizer=keras.optimizers.Adam(learning_rate=lr),\n","#         loss=\"categorical_crossentropy\",\n","#         metrics=[\"accuracy\"],\n","#     )\n","#     return model\n","\n","\n","# def build_model(hp):\n","#     units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n","#     activation = hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n","#     dropout = hp.Boolean(\"dropout\")\n","#     lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n","#     # call existing model-building code with the hyperparameter values.\n","#     model = call_existing_code(\n","#         units=units, activation=activation, dropout=dropout, lr=lr\n","#     )\n","#     return model\n","\n","def build_train_model(units, activation,lr, drop_out):\n","# LSTM MODEL\n","    input_timesteps= 20 - 1\n","    model = Sequential()\n","    # model.add(LSTM(units=units, input_shape=(input_timesteps, 1), return_sequences = True))\n","    model.add(LSTM(units=units, return_sequences = True))\n","    if drop_out:\n","        model.add(Dropout(rate=0.25))\n","    model.add(LSTM(units=units,return_sequences = True))\n","    model.add(LSTM(units=units,return_sequences =False))\n","    if drop_out:\n","        model.add(Dropout(rate=0.25))\n","    model.add(Dense(units=units, activation=activation))  \n","    model.add(Dense(1, activation='linear'))\n","    model.compile(loss='mean_squared_error',optimizer=keras.optimizers.Adam(learning_rate=lr))\n","    # Fit the model\n","    # model.fit(x_train,y_train,epochs=epochs,batch_size=batch_size)\n","    \n","    return model\n","    # model.predict(x_test)\n","    \n","    \n","def build_model(hp):\n","    units = hp.Int(\"units\", min_value=32, max_value=512, step=32)\n","    activation = hp.Choice(\"activation\", [\"relu\",\"tanh\"])\n","    dropout = hp.Boolean(\"dropout\")\n","    lr = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n","    # call existing model-building code with the hyperparameter values.\n","    model = build_train_model(\n","        units=units, activation=activation, drop_out=dropout, lr=lr\n","    )\n","    return model\n","    \n","    # In[44]:\n","    \n","    \n","    # model.predict(x_test)\n","\n","\n","# In[46]:\n","\n","def validation(model, x_test, y_test, y_test_ori, prediction_len, record_max, record_min):\n","\n","    #multi sequence predict\n","    data=x_test\n","    prediction_seqs = []\n","    window_size=sequence_length\n","    pre_win_num=int(len(data)/prediction_len)    \n","    for i in range(0,pre_win_num):\n","        curr_frame = data[i*prediction_len]\n","        predicted = []\n","        for j in range(0,prediction_len):\n","          temp=model.predict(curr_frame[newaxis,:,:])[0]\n","          predicted.append(temp)\n","          curr_frame = curr_frame[1:]\n","          curr_frame = np.insert(curr_frame, [window_size-2], predicted[-1], axis=0)\n","        prediction_seqs.append(predicted)\n","        \n","    # print(prediction_seqs)\n","    \n","    \n","    # In[48]:\n","    \n","    \n","    #de_predicted\n","    de_predicted=[]\n","    len_pre_win=int(len(data)/prediction_len)\n","    len_pre=prediction_len\n","    \n","    m=0\n","    for i in range(0,len_pre_win):\n","        for j in range(0,len_pre):\n","          de_predicted.append(prediction_seqs[i][j][0]*record_max[m]+record_min[m])\n","          m=m+1\n","    # print(de_predicted)\n","    \n","    \n","    # In[50]:\n","    \n","    \n","    error = []\n","    diff=y_test.shape[0]-prediction_len*pre_win_num\n","    \n","    for i in range(y_test_ori.shape[0]-diff):\n","        error.append(y_test_ori[i,] - de_predicted[i])\n","        \n","    squaredError = []\n","    absError = []\n","    for val in error:\n","        squaredError.append(val * val) \n","        absError.append(abs(val))\n","    \n","    error_percent=[]\n","    for i in range(len(error)):\n","        val=absError[i]/y_test_ori[i,]\n","        val=abs(val)\n","        error_percent.append(val)\n","    \n","    mean_error_percent=sum(error_percent) / len(error_percent)\n","    accuracy=1-mean_error_percent\n","    \n","    MSE=sum(squaredError) / len(squaredError)\n","    RMSE = math.sqrt(MSE)\n","    \n","    return RMSE, accuracy, de_predicted\n","    # In[50]:\n","\n"]}]}